{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data and display first 5 rows\n",
    "features = pd.read_csv(\"../processed_data/2018_Clusters_Ratios_AF.csv\")\n",
    "features.head(5)\n",
    "columns = features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"Name\" column to the index\n",
    "features = features.set_index('Name')\n",
    "\n",
    "# Drop \"Name\" column\n",
    "#features.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['cluster'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('cluster', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (312, 17)\n",
      "Training Labels Shape: (312,)\n",
      "Testing Features Shape: (105, 17)\n",
      "Testing Labels Shape: (105,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "#baseline_preds = test_features[:, feature_list.index('average')]\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "#baseline_errors = abs(baseline_preds - test_labels)\n",
    "#print('Average baseline error: ', round(np.mean(baseline_errors), 2))\n",
    "#Average baseline error:  5.06 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 25,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  3,  1, 14,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2,  0, 14,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 11,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_pred = rf.predict(test_features)\n",
    "confusion_matrix(test_labels, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 20  4  4 11 10 11  9  4  9  7  9 11 10  9  4 10  9 16  9 10  9 12 11\n",
      "  4  7  9  4 10  7  9 15  4 10 10  4 11  7  7  7  4  4  4  4  3  4  9  1\n",
      " 10  7  7  9  7  7 11  4 10 10  4  9 11 11  4  9  4 10  4  4 17  4  7  2\n",
      "  9  4  4  4 11  9 10  1 11  4 10  9 10 10  4  7 10  4  2  9  7  7  7  9\n",
      " 19 16  7  0 15  9  7  4 11]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.780952380952381"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify feature importance\n",
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02671701 0.04025036 0.03797245 0.13179443 0.03256649 0.0321568\n",
      " 0.04210209 0.028532   0.28645134 0.12306367 0.06146572 0.02817685\n",
      " 0.03505742 0.00803659 0.02590206 0.03390786 0.02584685]\n"
     ]
    }
   ],
   "source": [
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Net cash flow / Change in cash', 'Average Payables',\n",
      "       'Average Receivables', 'currentRatio', 'SG&A to Revenue',\n",
      "       'daysOfPayablesOutstanding', 'daysOfInventoryOutstanding',\n",
      "       'eBITperRevenue', 'Intangibles to Total Assets', 'Debt to Assets',\n",
      "       'Debt to Equity', 'Payout Ratio', 'ROE', 'R&D to Revenue', 'PE ratio',\n",
      "       'returnOnAssets', 'Dividend Yield', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
